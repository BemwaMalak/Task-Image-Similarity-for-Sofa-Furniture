{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Tuple, Any, Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../data/sofas/raw\"\n",
    "output_dir = \"../data/sofas/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePreprocessor(ABC):\n",
    "    \"\"\"Abstract base class for image preprocessing algorithms.\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def preprocess(self, image_path: str, save_path: Optional[str] = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Preprocess the input image.\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the input image\n",
    "            save_path (str, optional): Path to save the processed image\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Processed image\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all_processed_images(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Display each pair of original and processed images in separate figures.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Directory containing original images\n",
    "        output_dir (str): Directory containing processed images\n",
    "    \"\"\"\n",
    "    # Get list of processed images\n",
    "    processed_files = sorted([f for f in os.listdir(output_dir) if f.startswith('processed_')])\n",
    "    original_files = sorted([f.replace('processed_', '') for f in processed_files])\n",
    "    \n",
    "    # Plot each pair of images in a separate figure\n",
    "    for orig_file, proc_file in zip(original_files, processed_files):\n",
    "        # Original image\n",
    "        orig_path = os.path.join(input_dir, orig_file)\n",
    "        orig_img = cv2.imread(orig_path)\n",
    "        orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Processed image\n",
    "        proc_path = os.path.join(output_dir, proc_file)\n",
    "        proc_img = cv2.imread(proc_path)\n",
    "        proc_img = cv2.cvtColor(proc_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Create a new figure for each pair\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        # Add original image subplot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(orig_img)\n",
    "        plt.title(f'Original: {orig_file}')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Add processed image subplot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(proc_img)\n",
    "        plt.title(f'Processed: {proc_file}')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_sofas(input_dir: str, output_dir: str, preprocessor: ImagePreprocessor):\n",
    "    \"\"\"\n",
    "    Process all sofa images in a directory and save the processed versions.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Directory containing original sofa images\n",
    "        output_dir (str): Directory to save processed images\n",
    "        preprocessor (ImagePreprocessor): Instance of a preprocessor class that implements ImagePreprocessor\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each image\n",
    "    for img_file in os.listdir(input_dir):\n",
    "        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            input_path = os.path.join(input_dir, img_file)\n",
    "            output_path = os.path.join(output_dir, f'processed_{img_file}')\n",
    "            \n",
    "            # Process and save using the provided preprocessor\n",
    "            preprocessor.preprocess(input_path, output_path)\n",
    "            print(f\"Processed: {img_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GrabCut-based Sofa Segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The `SofaSegmenter` class implements an approach to segment sofas from images using OpenCV's GrabCut algorithm. It's specifically optimized for sofa images, assuming they typically occupy the central portion of the image.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "### 1. Image Preprocessing\n",
    "- Resizes large images while maintaining aspect ratio\n",
    "- Maximum dimension configurable (default: 800px)\n",
    "- Adds padding around segmented region\n",
    "\n",
    "### 2. Segmentation Process\n",
    "1. **Initial Mask Creation**\n",
    "   - Divides image into regions:\n",
    "     - Border (5% of image): Definite background\n",
    "     - Outer region (20-80% height, 10-90% width): Probable foreground\n",
    "     - Inner region (30-70% height, 20-80% width): Definite foreground\n",
    "\n",
    "2. **GrabCut Segmentation**\n",
    "   - Applies OpenCV's GrabCut algorithm\n",
    "   - Uses initial mask to guide segmentation\n",
    "   - Configurable number of iterations\n",
    "\n",
    "3. **Post-processing**\n",
    "   - Extracts largest contour\n",
    "   - Calculates bounding box\n",
    "   - Crops to sofa region with padding\n",
    "   - Scales back to original dimensions if needed\n",
    "\n",
    "## Usage Parameters\n",
    "- `padding`: Extra space around segmented sofa (default: 10px)\n",
    "- `max_size`: Maximum image dimension (default: 800px)\n",
    "- `iterations`: GrabCut iteration count (default: 1)\n",
    "\n",
    "## Input/Output\n",
    "- Input: RGB/BGR image file\n",
    "- Output: Segmented and cropped sofa image with background removed\n",
    "\n",
    "Based on the requirement of not using machine learning models, I think using GrabCut is a good option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SofaSegmenter(ImagePreprocessor):\n",
    "    \"\"\"Sofa segmentation and background removal using GrabCut algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self, padding: int = 10, max_size: int = 800, iterations: int = 1):\n",
    "        \"\"\"\n",
    "        Initialize the sofa segmenter.\n",
    "        \n",
    "        Args:\n",
    "            padding (int): Padding to add around the segmented sofa\n",
    "            max_size (int): Maximum dimension size for resizing while maintaining aspect ratio\n",
    "            iterations (int): Number of GrabCut iterations\n",
    "        \"\"\"\n",
    "        if padding < 0 or max_size <= 0 or iterations <= 0:\n",
    "            raise ValueError(\"Invalid parameters: padding must be >= 0, max_size and iterations must be > 0\")\n",
    "        \n",
    "        self.padding = padding\n",
    "        self.max_size = max_size\n",
    "        self.iterations = iterations\n",
    "        \n",
    "    def _resize_image(self, image: np.ndarray) -> Tuple[np.ndarray, float]:\n",
    "        \"\"\"\n",
    "        Resize image while maintaining aspect ratio if it exceeds max_size.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, float]: (Resized image, scale factor)\n",
    "        \"\"\"\n",
    "        height, width = image.shape[:2]\n",
    "        max_dim = max(height, width)\n",
    "        \n",
    "        if max_dim > self.max_size:\n",
    "            scale = self.max_size / max_dim\n",
    "            new_width = int(width * scale)\n",
    "            new_height = int(height * scale)\n",
    "            resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "            return resized, scale\n",
    "        return image, 1.0\n",
    "\n",
    "    def _create_initial_mask(self, height: int, width: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Create initial mask for GrabCut with sofa-specific regions.\n",
    "        \n",
    "        Args:\n",
    "            height (int): Image height\n",
    "            width (int): Image width\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Initialized mask with background/foreground regions\n",
    "        \"\"\"\n",
    "        # Initialize as probable background\n",
    "        mask = np.ones((height, width), np.uint8) * cv2.GC_PR_BGD\n",
    "        \n",
    "        # Border parameters\n",
    "        border = int(min(height, width) * 0.05)\n",
    "        \n",
    "        # sofa typically occupies the central portion of the image\n",
    "        sofa_regions = {\n",
    "            'outer': {'y': (0.2, 0.8), 'x': (0.1, 0.9), 'value': cv2.GC_PR_FGD},\n",
    "            'inner': {'y': (0.3, 0.7), 'x': (0.2, 0.8), 'value': cv2.GC_FGD}\n",
    "        }\n",
    "        \n",
    "        # Mark borders as definite background\n",
    "        mask[:border, :] = cv2.GC_BGD\n",
    "        mask[-border:, :] = cv2.GC_BGD\n",
    "        mask[:, :border] = cv2.GC_BGD\n",
    "        mask[:, -border:] = cv2.GC_BGD\n",
    "        \n",
    "        # Mark sofa regions\n",
    "        for region in sofa_regions.values():\n",
    "            y_start = int(height * region['y'][0])\n",
    "            y_end = int(height * region['y'][1])\n",
    "            x_start = int(width * region['x'][0])\n",
    "            x_end = int(width * region['x'][1])\n",
    "            mask[y_start:y_end, x_start:x_end] = region['value']\n",
    "        \n",
    "        return mask\n",
    "\n",
    "    def _get_bounding_box(self, mask: np.ndarray) -> Tuple[int, int, int, int]:\n",
    "        \"\"\"\n",
    "        Get bounding box coordinates from the largest contour in the mask.\n",
    "        \n",
    "        Args:\n",
    "            mask: Binary mask\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[int, int, int, int]: (x, y, width, height) of bounding box\n",
    "        \"\"\"\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            return cv2.boundingRect(largest_contour)\n",
    "        return (0, 0, mask.shape[1], mask.shape[0])\n",
    "\n",
    "    def _segment_sofa(self, image: np.ndarray) -> Tuple[np.ndarray, Tuple[int, int, int, int]]:\n",
    "        \"\"\"\n",
    "        Segment sofa from image using GrabCut algorithm.\n",
    "        \n",
    "        Args:\n",
    "            image: Input BGR image\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, Tuple[int, int, int, int]]: (Segmented image, bounding box)\n",
    "        \"\"\"\n",
    "        height, width = image.shape[:2]\n",
    "        mask = self._create_initial_mask(height, width)\n",
    "        \n",
    "        background_model = np.zeros((1, 65), np.float64)\n",
    "        foreground_model = np.zeros((1, 65), np.float64)\n",
    "        \n",
    "        # Perform GrabCut segmentation\n",
    "        cv2.grabCut(image, mask, None, background_model, foreground_model, \n",
    "                   self.iterations, cv2.GC_INIT_WITH_MASK)\n",
    "        \n",
    "        # Create binary mask and apply it\n",
    "        binary_mask = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "        segmented_image = cv2.bitwise_and(image, image, mask=binary_mask)\n",
    "        \n",
    "        return segmented_image, self._get_bounding_box(binary_mask)\n",
    "\n",
    "    def preprocess(self, image_path: str, save_path: Optional[str] = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Preprocess sofa image using GrabCut-based segmentation.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to input image\n",
    "            save_path: Optional path to save the processed image\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Processed image with background removed and cropped\n",
    "        \"\"\"\n",
    "        # Load and validate image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image from {image_path}\")\n",
    "        \n",
    "        # Process image at reduced size for efficiency\n",
    "        resized_image, scale = self._resize_image(image)\n",
    "        segmented_image, (x, y, w, h) = self._segment_sofa(resized_image)\n",
    "        \n",
    "        # Scale coordinates back to original size if needed\n",
    "        if scale != 1.0:\n",
    "            x, y, w, h = [int(val / scale) for val in (x, y, w, h)]\n",
    "            segmented_image = cv2.resize(segmented_image, (image.shape[1], image.shape[0]), \n",
    "                                       interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Add padding and ensure coordinates are within image bounds\n",
    "        x = max(0, x - self.padding)\n",
    "        y = max(0, y - self.padding)\n",
    "        w = min(image.shape[1] - x, w + 2 * self.padding)\n",
    "        h = min(image.shape[0] - y, h + 2 * self.padding)\n",
    "        \n",
    "        # Crop to sofa region\n",
    "        result = segmented_image[y:y+h, x:x+w]\n",
    "        \n",
    "        if save_path:\n",
    "            cv2.imwrite(save_path, result)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = SofaSegmenter(\n",
    "    padding=20,\n",
    "    max_size=800\n",
    ")\n",
    "\n",
    "process_all_sofas(input_dir, output_dir, preprocessor)\n",
    "display_all_processed_images(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
